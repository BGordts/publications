\chapter{Computer Science and Game Theory}

\begin{defi}
A \term{game} $A$ consists of the state of the \term{game objects} ($S$), the input of the system (player's input, $M$) and the abstract control system (time-independent, $F$) which governs the $S$ under the current $M$:
\begin{equation}
\mbox{Game }A=\tuple{S,M,F}
\end{equation}
\cite{journals/procedia/KosmadoudiLRSLSS12}
\end{defi}

\begin{defi}
\term{Neutral element} of $M$ (\term{empty input}, $\epsilon$) the current state of the game ($s$) with input ($p$) broken down into two consecutive inputs ($m$,$n$):
\begin{equation}
\group{
\fun{F}{s,\epsilon}=s\mbox{ with }s\in S\\
\fun{F}{s,mn}=\fun{F}{\fun{F}{s,m},n}\mbox{ with } s\in S\mbox{ and }m,n\in M
}
\end{equation}
\cite{journals/procedia/KosmadoudiLRSLSS12}
\end{defi}

\begin{defi}[Maxset, Minset]
The \term{maxset} $X^M$ is that subset of $X$ at which it is MAX's turn to make a move. The \term{minset} $X^m$ is that subset of $X$ at which it is MIN's turn to make a move.
\cite{conf/ijcai/Boffey73}
\end{defi}

\begin{defi}[Evaluation function, Better position]
An \termabbrev{evaluation function}{EF} over a game graph $\tuple{X,\Gamma}$ is a single valued function $\funsig{f}{X}{\RRR}$. If $\ffun{x}>\ffun{y}$ then $x$ is said to be a \term{better position} than $y$ under $f$.
\cite{conf/ijcai/Boffey73}
\end{defi}

\begin{defi}[Strategy $\calS_o$]
$\calS_o$ is that \term[Strategy $\calS_o$]{strategy} which leads to move $xy*$ being made from position $x$ where:
\begin{equation}
\group{\ffun{x*}=\displaystyle\max_{y\in\Gamma_x}\ffun{y}\mbox{ if }x\in X^M\\
\ffun{x*}=\displaystyle\min_{y\in\Gamma_x}\ffun{y}\mbox{ if }x\in X^m}
\end{equation}
Ties for $y*$ are broken by some subsidiary rule.
\cite{conf/ijcai/Boffey73}
\end{defi}

\begin{defi}[Locally equivalent evaluation functions, Locally perfect evaluation function]
Evaluation functions $f$ and $g$ are \term[locally equivalent evaluation functions]{locally equivalent} if
\begin{equation}
\ffun{x}>\ffun{y}\mbox{ whenever }\gfun{x}>\gfun{y}
\end{equation}
where $x,y\in\Gamma_w$ for some $w\in X$. $f$ is \term[locally perfect evaluation function]{locally perfect} if it is locally equivalent to $\lambda_{mm}^w$.
\cite{conf/ijcai/Boffey73}
\end{defi}

\begin{defi}[Probabilistic evaluation function]
A \termabbrev{probabilistic evaluation function}{PEF} over a game graph $\tuple{X,\Gamma}$ is a bounded function $\funsig{p}{X\times\RRR}{\RRR}$ with $\pfun{x,r}\geq0$, $\displaystyle\int{\pfun{x,r}\ dr}=1$ and $\pfun{x,r}=0$ outside some finite range $\fun{r_1}{x}\leq r\leq \fun{r_2}{x}$.
\cite{conf/ijcai/Boffey73}
\end{defi}

\begin{defi}[Strategy $\calS_o'$]
$\calS_o'$ is that \term[Strategy $\calS_o'$]{strategy} which leads to move $xy*$ being made from position $x$ where:
\begin{equation}
\group{\fun{v}{x*}_p=\displaystyle\max_{y\in\Gamma_x}\fun{v}{y}_p\mbox{ if }x\in X^M\\
\fun{v}{x*}_p=\displaystyle\min_{y\in\Gamma_x}\fun{v}{y}_p\mbox{ if }x\in X^m}
\end{equation}
\cite{conf/ijcai/Boffey73}
\end{defi}

\begin{defi}[(Constant) decision rule, Preference function, Preferred move]
A (constant) \termor{decision rule}{preference function} for MAX is a single valued function \funsig{\sigma_M}{X}{X} with $\fun{\sigma_M}{x}\in\Gamma_x$. $x\mapsto\fun{\sigma_M}{x}$ is MAX's \term{preferred move} from $x$. A preference function $\sigma_m$ for MIN can be defined in an analogous way.
\cite{conf/ijcai/Boffey73}
\end{defi}

\begin{defi}[(Constant) preference pair]
If $\sigma_M$ and $\sigma_m$ are preference functions for MAX and MIN respectively then $\sigma=\brak{\sigma_M,\sigma_m}$ is termed a (constant) \term{preference pair} on $\brak{X,\Gamma}$.
\cite{conf/ijcai/Boffey73}
\end{defi}

\begin{defi}[Strategy order relation $\leq_\sigma$]
If $u,v\in X$ and $\sigma$ is a preference pair on $\brak{X,\Gamma}$ then \term[Strategy order relation $\leq_\sigma$]{$u\geq_\sigma v$} \iffTx{} there exists an element $t\in X$ such that
\begin{enumerate}
 \item $u,v\in\Gamma^t$
 \item $u=\fun{\sigma_M}{t}$ or $v=\fun{\sigma_m}{t}$
\end{enumerate}
\cite{conf/ijcai/Boffey73}
\end{defi}

\begin{defi}[Evaluation function reproduces a preference pair]
An evaluation function $f$ over $\brak{X,\Gamma}$ \term[Evaluation function reproduces]{reproduces} a preference pair $\sigma$ (with respect to a strategy $\calS_0$) if $\ffun{x}>\ffun{y}$ whenever $x>_\sigma y$.
\cite{conf/ijcai/Boffey73}
\end{defi}

\begin{defi}[Strategy order relation $\leq_\sigma^*$]
If $u,v\in X$ and $\sigma$ is a preference pair on $\brak{X,\Gamma}$ then \term[Strategy order relation $\leq_\sigma^*$]{$u\geq_\sigma^* v$} \iffTx{} there exists is a sequence $u=w_0,w_1,\ldots,w_s=v$ such that $w_i>_\sigma w_{i-1}$, $i=1,2,\ldots,s$
\cite{conf/ijcai/Boffey73}
\end{defi}

\begin{defi}[Fully consistent strategy]
$\sigma$ is \term[Fully consistent strategy]{fully consistent} if $C_{\pi_1}=C_{\pi_2}$ for any pair of paths $\pi_1,\pi_2$ with the same endpoints.
\cite{conf/ijcai/Boffey73}
\end{defi}

\begin{defi}[(Variable) preference function]
A \term{(Variable) preference function} for MAX is a single-valued function \funsig{\tau_M}{X^M}{\Gamma\times X^M\setminus I} where $I$ is the unit interval $I=\accol{x|0\leq x\leq 1}$ and
\begin{enumerate}
 \item $\fun{\tau_M}{x,u}=0$ if $u\notin\Gamma_x$
 \item $\fun{\tau_M}{x,u}\geq 0$ if $u\in\Gamma_x$
 \item $\displaystyle\sum_{u\in\Gamma_x}{\fun{\tau_M}{x,u}}=1$
\end{enumerate}
\fun{\tau_M}{x,u} can be thought of as the probability that, when in position $x$, MAX will choose to move to position $u$. A variable preference rule $\tau_m$ for MIN can be defined in an analogous way.
\cite{conf/ijcai/Boffey73}
\end{defi}

\begin{defi}[(Variable) preference pair]
If $\tau_M$ and $\tau_m$ are variable preference functions for MAX and MIN respectively then $\tau=\brak{\tau_M,\tau_m}$ is termed a \term{(variable) preference pair} on \brak{X,\Gamma}.
\cite{conf/ijcai/Boffey73}
\end{defi}
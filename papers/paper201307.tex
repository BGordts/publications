\documentclass[a4paper,10pt]{article}
\usepackage{bnaic13/bnaic,hyperref,amsthm,amsfonts,todonotes}

%opening
\title{\emph{ParHyFlex}:\\A Framework for Parallel Hyper-heuristics}
\author{Willem Van Onsem}% \affila
\date{\textit{Department of Computer Science, KU Leuven}}%\affila\ 

\newcommand{\seclab}[1]{\label{sec:#1}}
\newcommand{\secref}[1]{\ref{sec:#1}}
\newcommand{\ssclab}[1]{\label{ssc:#1}}
\newcommand{\sscref}[1]{\ref{ssc:#1}}

\newcommand{\tupl}[1]{\ensuremath{\left\langle #1 \right\rangle}}
\newcommand{\abs}[1]{\ensuremath{\left| #1 \right|}}
\newcommand{\accl}[1]{\ensuremath{\left\{ #1 \right\}}}
\newcommand{\brak}[1]{\ensuremath{\left( #1 \right)}}
\newcommand{\fun}[2]{\ensuremath{#1\brak{#2}}}
\newcommand{\funm}[2]{\fun{\mbox{#1}}{#2}}

\newcommand{\BoolSet}{\accl{\mbox{true},\mbox{false}}}

% \makeatletter
% \newcommand{\emph}[1]{
% \@ifundefined{r@#1}{\label{#1}\emph{#1}}{#1}
% }
% \makeatother

\newcommand{\calS}{\ensuremath{\mathcal{S}}}
\newcommand{\calE}{\ensuremath{\mathcal{E}}}
\newcommand{\calA}{\ensuremath{\mathcal{A}}}

\newcommand{\RR}{\ensuremath{\mathbb{R}}}

\newcommand{\guard}[1]{\ensuremath{\left\{\begin{array}{ll}#1\end{array}\right.}}

\theoremstyle{definition}
\newtheorem{definition}{Definition}

\pagestyle{empty}

\begin{document}
\ttl
\thispagestyle{empty}


\begin{abstract}
\noindent
Hyper-heuristics are a generic method to solve optimization problems. In this paper we present a framework called \emph{ParHyFlex} supporting the implementation of parallel hyper-heuristics. Results are presented for the Maximal Satisfiability Problem (Max-Sat), Circle Positioning Problem (CPP) and Frequency Assignment Problem (FAP).
\end{abstract}

\section{Introduction}
\seclab{hyper-heuristics}
Formally, an \emph{optimization problem} is defined as follows:
\begin{definition}[Optimization problem]
We define an \emph{optimization problem} as a tuple $\tupl{\calS,h,f}$ with $\calS$ a set of \emph{configurations}, $h:\calS\rightarrow\BoolSet$ a \emph{hard constraint} and $f:\calS\rightarrow\RR$ an \emph{evaluation function}. In such a problem one searches for a configuration satisfying the hard constraint $h$ with a minimal value regarding the evaluation function $f$. Other configurations satisfying the hard constraint are called \emph{solutions}.
\end{definition}


% In order to solve optimization problems, several methods exist. For some problems one can implement a straightforward or tailor-based algorithm solving the problem in polynomial time. In most cases however this is not possible. In order to solve such problems, one needs to enumerate a large number of configurations.
% 
% \paragraph{}
% Two families of such algorithms are \emph{branch-and-bound} and \emph{metaheuristics}. In the case one uses a \emph{branch-and-bound approach}, solutions are generated in a structured way. Since all potential solutions are generated with a fitness-value of at least the bound at the moment of generation, once all potential solutions are generated, we can be sure we have generated the exact solution.
% 
% \paragraph{}
% A problem with \emph{branch-and-bound} however is that if the space of potential configurations is quite large, this method becomes infeasible. Since the method searches the solutions in a structured way, one does not expect to find strong solutions if only a small amount of the configuration space is enumerated. This effect is mainly supported by the common belief that similar solutions often have a similar fitness-value.
% 
% \paragraph{}
% \emph{Metaheuristics} try to tackle the problem in another way. A \emph{metaheuristic} considers one or more solutions and iteratively tries to improve these solutions by slightly modifying these solutions. The algorithms who calculate a new solution out of one or more solutions are called \emph{heuristics} or \emph{transition functions}.
% 
% \paragraph{}
% When implementing a \emph{meta-heuristic}, it is important to design good \emph{transition functions}. However it is not clear how these \emph{transition functions} should be designed. A \emph{hyper-heuristic} aims to solve this problem by considering a (large) set of transition functions and learn which transition function perform well in specific conditions.
% 
% \paragraph{}
% Todays \emph{hyper-heuristics} fail to compete with tailor-based approaches. One can improve performance by performing the algorithm in parallel. In this paper we present a framework who supports the implementation of \emph{parallel hyper-heuristics}.%TODO
% 
% \paragraph{}
% This paper is organized as follows: in section \secref{parhyp} we discuss some implementations of parallel hyper-heuristic systems. A framework called \emph{HyFlex} is discussed in section \secref{hyflex}. This framework formed the basis of our own work. In section \secref{parhyflex} we present our own work and discuss the components who try to speed up convergence. In section \secref{results} we present results regarding the performance of the implemented framework and compare these results with the other frameworks.%In section \secref{hyper-heuristics} we give a short introduction on hyper-heuristics. 

\section{Related work}
\seclab{parhyp}

Performing \emph{hyper-heuristics} in parallel has the potential to speed up convergence towards good solutions or make the result more robust. This research domain however is currently quite sparse. \emph{Leon, Miranda and Segura}\cite{} implemented a \emph{parallel hyper-heuristic} using a \emph{multi-objective self-adaptive Island-based model}.

\paragraph{}
\emph{Multiobjectivisation} is a process where the initial evaluation function is divided into several somehow similar functions. Such decomposition allows the system to escape from a local optimum by one evaluation function by using another one. A problem with multiobjectivisation however is that the different objectives can interfere and cancel each other out. In order to prevent this one can calculate a weighted sum of the different objectives. This however introduces new parameters. Determining optimal parameter settings is quite hard.

\paragraph{}
The system focuses on genetic algorithms where each process maintains a set of solutions called a \emph{deme}. In each iteration one or more solutions are selected. By using a special type of \emph{recombination operator} who take two or more solutions, the features of two solutions are recombined into a new solution. In an \emph{Island-based} approach, some solutions are exchanged between the different processors. The topology of processors who exchange solutions is modified dynamically to boost performance.

\paragraph{}
The system works in the \emph{master-slave} paradigm. A set of processors called \emph{workers} execute a \emph{genetic algorithm}. The parameters and \emph{transition functions} of the \emph{workers} are assigned by a special processor called the \emph{master island}. When a stop criterion is reached, a worker sends the results to the \emph{master island} and obtains a new \emph{execution strategy}. The processor takes the final population of the previous run as the new initial population.%The \emph{master island} decides which \emph{low-level configuration} will be applied at each \emph{worker}%One processor is called the \emph{master island} while the other processors

\paragraph{}
The framework is tested with the \emph{Antenna Positioning Problem (APP)}\cite{} and the \emph{Frequency Assignment Problem (FAP)}\cite{}. The researchers report a \emph{speed-up} but the results but the results are still not comparable with tailor-based sequential approaches.

%\paragraph{}
%\emph{Rattadilok, Gaw and Kwan} furthermore implemented a parallel hyper-heuristic to solve scheduling problems. %They consider a set of agents who aim to schedule their tasks satisfying the given constraints bu

\todo{ander systeem bespreken?}

\section{\emph{ParHyFlex}}
\seclab{parhyflex}

\subsection{\emph{HyFlex}}
In 2009 \emph{Burke et al.}\cite{} published a framework supporting the implementation of \emph{hyper-heuristics}. The framework was implemented in \emph{Java} and contained four problems. One implements a problem by providing an implementation on how a solution is represented together with \emph{transition functions} and an \emph{objective function}. To tackle the implemented problems, one also has to build a \emph{hyper-heuristic} as well. Such \emph{hyper-heuristic} can apply the given \emph{transition functions} on a set of solutions and evaluate the results based on the \emph{objective function}. The \emph{hyper-heuristic} however has no knowledge about the problem it is solving neither does it know the details of the different \emph{transition functions}. Therefore a \emph{hyper-heuristic} is implemented to solve a large range of optimization problems.

\subsection{\emph{Overview}}

\emph{ParHyFlex}\footnote{The source code is available at \url{http://goo.gl/AyvHA}.} is a variant of the \emph{HyFlex} framework that should make it easy to run \emph{hyper-heuristics} on parallel systems. Based on the framework, one can potentially implement a \emph{hyper-heuristic} without the knowledge the algorithm will run in parallel. The framework is implemented in \emph{Java}, communication is handled using the popular \emph{Message Passing Interface (MPI)} protocol.

\paragraph{}
The implementation uses a \emph{peer-to-peer} approach where each processor runs its own (potentially different) \emph{hyper-heuristic} and occasionally shares solutions with the other processors. Since similar solutions will probably have a similar fitness-value, it can be profitable to prevent the processors from exploring solutions in the same \emph{neighborhood}. Finally, the framework provides a communication mechanism so the different \emph{hyper-heuristics} can cooperate with each other.

\subsection{Implementing a problem}

\subsection{Exchanging solutions}
\seclab{exchangingsolutions}
As discussed before, the \emph{Island model}\cite{} is a paradigm where different \emph{meta-heuristics} exchange solutions to speed up convergence. %When \emph{parallel meta-heuristics} exchanging solutions, this yields in general better results and is widely known as the \emph{Island model}\cite{islandmodel}
In the \emph{Island model}, one considers different sets of solutions. On each of these sets, \emph{transition functions} are applied. Occasionally, solutions from one set are exchanged with another set.
By using special \emph{transition functions}, one can \emph{recombine} the good qualities of several solutions into a new solution. Since the exchange happens occasionally however the different sets can each develop strong solutions with different properties. The framework provides different exchange strategies and the solutions are exchanged by unreliable asynchronous communication.% who take as input two or more solutions

\subsection{Generating experience}
\seclab{generatingexperience}
Modern SAT solvers try to speed up the search for a correct solution by learning new clauses on the fly. Such constraints can be considered experience. An advantage of such experience is that it can be shared with other processors and therefore speed up the search.

\paragraph{}
A similar concept is implemented \emph{ParHyFlex}. The system considers experience to be a set of \emph{enforceable constraints} who are probably true. This is in contrast with clause learners who only learn clauses who are certainly true. We define an \emph{enforceable constraint} as follows:
\begin{definition}[Enforceable constraint]
An \emph{enforceable constraint} $e$ is a 3-tuple $\tupl{e_0,e^+,e^-}$ with $e_0:\calS\rightarrow\BoolSet$ a function who checks if a given solution satisfies the constraint. $e^+:\calS\rightarrow\calS$ is a function who slightly modifies a solution such that the resulting solution satisfies the constraint. $e^-:\calS\rightarrow\calS$ is a function who slightly modifies a solution such that the resulting solution does not satisfy the constraint. We denote the set of all representable \emph{enforceable constraint} for a \emph{certain} problem $P$ as $\calE_P$.
\end{definition}
\paragraph{}
In order to generate such constraints, one needs a function who has knowledge of the problem and can generate constraints based on a set of solutions. We call such function a \emph{hypothesis generator}. Evidently such function is a part of the problem dependent component in the \emph{hyper-heuristic}.
\begin{definition}[Hypothesis generator]
A \emph{hypothesis generator} is a problem dependent function $h_P:\calS^{n_h}\rightarrow\calE_P$ who generates an \emph{enforceable constraint} out of one or more \emph{solutions}.
\end{definition}
\emph{Enforceable constraints} generated by a \emph{hypothesis generator} are stored in a set called the \emph{experience set}. This set maintains a fixed number of constraints. Occasionally constraints are eliminated. This procedure is discussed in \sscref{maintainingexperience}.

\subsection{Controlling the search space}
\seclab{controllingsearchspace}
SAT solvers try to exploit the learned clauses by eliminating large parts of the search tree. Based on the \emph{experience set} introduced in the previous subsection, one can manipulate the set of considered solutions as well. Therefore we first introduce the concept of a \emph{search space}.
\begin{definition}[Search space]
A \emph{search space} $\calA$ is a tuple $\tupl{A^+,A^-}$ containing two sets of \emph{enforceable constraints}: \emph{positive constraints} $a^+_i\in A^+$ and \emph{negative constraints} $a^-_i\in A^-$. A \emph{search space} contains a \emph{solution} $s$ if at least one \emph{positive constraint} $a^+_i\in A^+$ is satisfied and all \emph{negative constraints} $a^-_i\in A^-$ are not satisfied. A \emph{solution} can be \emph{corrected} so it is an element of a \emph{search space} by using the \emph{transition functions} $e^+$ and $e^-$ provided by the \emph{enforceable constraints} in the two sets.%should be able to modify a solution minimally in such way the solution satisfies or not satisfies that constraint. By modifying a generated solution so it satisfies at least one positive constraint and does not satisfy any negative constraints, one can force the system to only search for solutions in a limited subset
\end{definition}
\paragraph{}
Constraints in the \emph{search space} can potentially interact with each other: one \emph{enforceable constraint} can undo the modification of another one. Resolving such conflicts can be computationally expensive and is potentially impossible. The \emph{ParHyFlex} framework does not handle such interactions. A search space is enforced in a \emph{fuzzy way}: occasionally \emph{corrected} solutions will not be part of the intended \emph{search space}.

\paragraph{}
One can generate a \emph{search space} by using a copying subset of the \emph{enforceable constraints} in the \emph{experience set} to the \emph{positive set}. When machines search the same region, there is a risk that most machines get stuck in similar local optima. Escaping these optima can be quite cumbersome since the exchanged solutions are similar as well. \emph{ParHyFlex} aims to prevent this by negotiating about a new search space: when a machine uses a certain constraint in the \emph{positive set}, the other machines will put this constraint in their \emph{negative set}. Occasionally new \emph{search spaces} are negotiated so eventually the entire set of solutions is accessible.

\subsection{Maintaining experience}
\ssclab{maintainingexperience}
Generated \emph{enforceable constraints} are not guaranteed to be true. Therefore the system should be aware of new solutions and continuously checks if strong solutions still satisfy these constraints. This is a task that is handled by the \emph{ParHyFlex} framework. Each time a new solution is generated, the system checks which constraints are satisfied. Based on the fitness-value of the solution, one can evaluate the \emph{enforceable constraints}. Occasionally the system removes one or more of these constraints if good solutions no longer satisfy these constraints.

\paragraph{}
Even when the generated solutions satisfying a constraint yield better results, this does not necessarily mean that this constraint is true for the best solutions. For instance a large set of suboptimal solutions can satisfy the constraint while better solutions don't satisfy the constraint at all. Since the \emph{enforceable constraints} in the \emph{experience set} eventually form the \emph{search space}, such constraints can prevent further improvement. Therefore this mechanism sometimes eliminates constraints who are considered to perform well. The system uses a probabilistic mechanism where the probability of elimination is proportional to the performance of the constraint. Eventually however, every constraint will be eliminated.%Such constraints are not guaranteed to be true, therefore the system continuous checks if the newly generated solutions still satisfy these constraints. If the generated constraints generally are satisfied by strong solutions, the system is likely to keep the constraint.

\subsection{Exchanging experience}
\seclab{exchangingexperience}
Since each machine is constrained by a \emph{search space}, the generated solutions are somehow similar. Therefore the evaluation of \emph{enforceable constraints} is quite subjective. In order to yield better results, a part of the \emph{experience set} is occasionally shared with the other processors. This gives the opportunity to evaluate the constraints in a different setting. Potentially the constraints can become part of the \emph{search space} of a different processor.%Therefore strong solutions generated by one machine may satisfy a certain \emph{enforceable constraint} while strong solutions 
% Since it is a common belief that similar solutions are more or less equally strong, we expect we can find interesting regions based on the solutions in the neighborhood. When such solutions are found, it is therefore 

\section{Results}
\seclab{results}

\subsection{Environment}
In order to test the framework, we have implemented a hyper-heuristic based on the \emph{AdapHH}\cite{} algorithm of Mustafa M\i{}s\i{}r. The algorithm was tested on the following problems: \emph{Maximal Satisfiability}, \emph{Frequency Assignment} and \emph{Circle Positioning}. The problems are briefly described in subsection \sscref{problemset}.%In the circle positioning problem, one tries to determine the location of a set of circles withing a large circle reducing the overlap of each pair of two circles.
\paragraph{}
The tests were performed on machines with an \emph{Intel i5 2400} processor\footnote{$4\times 3.10\mbox{ GHz}$ , $6\mbox{ MiB}$ cache.} and $3.7\mbox{ GiB}$ memory running the \emph{Ubuntu 12.04} operating system. The network uses \emph{Gigabit Ethernet} and is organized with a centralized switch.

\subsection{Problem Set}
\ssclab{problemset}
The \emph{Maximal Satisfiability Problem (Max-Sat)} is a popular problem where given a set of clauses the algorithm searches for a configuration such that the boolean variables satisfy the largest amount of clauses.

\paragraph{}
In the \emph{Circle Positioning Problem (CPP)} one is given a set of circles\footnote{Two circles may differ in radius.} and a large circle. One can search locations for these circles such that the total area of overlap and the area outside the large circle is minimized. Since the domains of the $x$ and $y$ coordinates of the circles are all representable floating point numbers, this problem cannot easily be solved by a \emph{branch-and-bound algorithm}.

\paragraph{}
Finally in the \emph{Frequency Assignment Problem (FAP)} one is given a set of transceivers $\accl{t_1,\ldots,t_n}$. Each transceiver $t_i$ can operate on a set of frequencies $\accl{f_{i\,1},\ldots,f_{i\ m_i}}$ some of the transceivers can operate on the same frequency. Each of the transceivers operates in one of the sectors $\accl{s_1,\ldots,s_k}$. A transceiver $t_i$ is placed in sector \fun{s}{t_i} and some transceivers share a sector. One tries to find a configuration where a transceiver $t_i$ is assigned a frequency $\fun{f}{t_i}$ and the total interference is minimized. The interference between two transceivers $t$ and $u$ is defined as:
\begin{equation}
\funm{interference}{t,u}=\guard{
\infty&s_t=s_u\wedge\abs{\fun{f}{t}-\fun{f}{u}}<2\\
\funm{erf}{c_1-\mu_{s_t\,s_u}/\sigma_{s_t\,s_u}}&s_t=s_u\wedge\mu_{s_t\,s_u}>0\wedge\abs{\fun{f}{t}-\fun{f}{u}}=0\\
\funm{erf}{c_1-c_2-\mu_{s_t\,s_u}/\sigma_{s_t\,s_u}}&s_t=s_u\wedge\mu_{s_t\,s_u}>0\wedge\abs{\fun{f}{t}-\fun{f}{u}}=1\\
0&\mbox{otherwise}
}
\end{equation}
Where $s_t$ and $s_u$ are the sectors of the transceivers $t$ and $u$. $\mu_{s_t\,s_u}$ and $\sigma_{s_t\,s_u}$ represent the mean and average in the signal-to-inference (C/I) ratio between the sectors $s_t$ and $s_u$. $c_1$ and $c_2$ are the threshold values of acceptable quality. Finally $\funm{erf}{x}$ is defined as the the error-function. The total interference is calculated by taking the sum over every two different transceivers. Instead of infinity most implementations use a large constant to distinct between different amounts of total interference. This problem is tackled by the framework of \emph{Leon, Miranda and Segura} as discussed in section \secref{parhyp}.

\subsection{Experimental results}
\todo{Wachten op resultaten voor CPP en FAP.}


\section{Conclusions and Further Work}
\todo{Wachten op resultaten voor CPP en FAP.}

\bibliographystyle{plain}
\bibliography{referenties}
\end{document}

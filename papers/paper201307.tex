\documentclass[a4paper,10pt]{article}
\usepackage{bnaic13/bnaic,hyperref,amsthm,amsfonts,tikz,todonotes}
\usetikzlibrary{calc,fit,positioning}

%opening
\title{\emph{ParHyFlex}:\\A Framework for Parallel Hyper-heuristics}
\author{Willem Van Onsem}% \affila
\date{\textit{Department of Computer Science, KU Leuven}}%\affila\ 

\newcommand{\seclab}[1]{\label{sec:#1}}
\newcommand{\secref}[1]{\ref{sec:#1}}
\newcommand{\ssclab}[1]{\label{ssc:#1}}
\newcommand{\sscref}[1]{\ref{ssc:#1}}

\newcommand{\tupl}[1]{\ensuremath{\left\langle #1 \right\rangle}}
\newcommand{\abs}[1]{\ensuremath{\left| #1 \right|}}
\newcommand{\accl}[1]{\ensuremath{\left\{ #1 \right\}}}
\newcommand{\brak}[1]{\ensuremath{\left( #1 \right)}}
\newcommand{\fun}[2]{\ensuremath{#1\brak{#2}}}
\newcommand{\funm}[2]{\fun{\mbox{#1}}{#2}}

\newcommand{\HypSet}{\calH}
\newcommand{\constr}{\calH}

\newcommand{\BoolSet}{\accl{\mbox{true},\mbox{false}}}

% \makeatletter
% \newcommand{\emph}[1]{
% \@ifundefined{r@#1}{\label{#1}\emph{#1}}{#1}
% }
% \makeatother

\newcommand{\calS}{\ensuremath{\mathcal{S}}}
\newcommand{\calH}{\ensuremath{\mathcal{H}}}
\newcommand{\calE}{\ensuremath{\mathcal{E}}}
\newcommand{\calA}{\ensuremath{\mathcal{A}}}

\newcommand{\RR}{\ensuremath{\mathbb{R}}}

\newcommand{\guard}[1]{\ensuremath{\left\{\begin{array}{ll}#1\end{array}\right.}}

\theoremstyle{definition}
\newtheorem{definition}{Definition}

\pagestyle{empty}

\begin{document}
\ttl
\thispagestyle{empty}


\begin{abstract}
\noindent
Hyper-heuristics are a generic method to solve optimization problems. In this paper we present a framework called \emph{ParHyFlex} supporting the implementation of parallel hyper-heuristics. Results are presented for the Maximal Satisfiability Problem (Max-Sat), Circle Positioning Problem (CPP) and Frequency Assignment Problem (FAP).
\end{abstract}

\section{Introduction}
\seclab{hyper-heuristics}
Formally, we \emph{optimization problem} is defined as follows:
\begin{definition}[Optimization problem]
We define an \emph{optimization problem} as a tuple $\tupl{\calS,h,f}$ with $\calS$ a set of \emph{configurations}, $h:\calS\rightarrow\BoolSet$ a \emph{hard constraint} and $f:\calS\rightarrow\RR$ an \emph{evaluation function}. In such a problem one searches for a configuration satisfying the hard constraint $h$ with a minimal value regarding the evaluation function $f$. Other configurations satisfying the hard constraint are called \emph{solutions}.
\end{definition}


% In order to solve optimization problems, several methods exist. For some problems one can implement a straightforward or tailor-based algorithm solving the problem in polynomial time. In most cases however this is not possible. In order to solve such problems, one needs to enumerate a large number of configurations.
% 
% \paragraph{}
% Two families of such algorithms are \emph{branch-and-bound} and \emph{metaheuristics}. In the case one uses a \emph{branch-and-bound approach}, solutions are generated in a structured way. Since all potential solutions are generated with a fitness-value of at least the bound at the moment of generation, once all potential solutions are generated, we can be sure we have generated the exact solution.
% 
% \paragraph{}
% A problem with \emph{branch-and-bound} however is that if the space of potential configurations is quite large, this method becomes infeasible. Since the method searches the solutions in a structured way, one does not expect to find strong solutions if only a small amount of the configuration space is enumerated. This effect is mainly supported by the common belief that similar solutions often have a similar fitness-value.
% 
% \paragraph{}
% \emph{Metaheuristics} try to tackle the problem in another way. A \emph{metaheuristic} considers one or more solutions and iteratively tries to improve these solutions by slightly modifying these solutions. The algorithms who calculate a new solution out of one or more solutions are called \emph{heuristics} or \emph{transition functions}.
% 
% \paragraph{}
% When implementing a \emph{meta-heuristic}, it is important to design good \emph{transition functions}. However it is not clear how these \emph{transition functions} should be designed. A \emph{hyper-heuristic} aims to solve this problem by considering a (large) set of transition functions and learn which transition function perform well in specific conditions.
% 
% \paragraph{}
% Todays \emph{hyper-heuristics} fail to compete with tailor-based approaches. One can improve performance by performing the algorithm in parallel. In this paper we present a framework who supports the implementation of \emph{parallel hyper-heuristics}.%TODO
% 
% \paragraph{}
% This paper is organized as follows: in section \secref{parhyp} we discuss some implementations of parallel hyper-heuristic systems. A framework called \emph{HyFlex} is discussed in section \secref{hyflex}. This framework formed the basis of our own work. In section \secref{parhyflex} we present our own work and discuss the components who try to speed up convergence. In section \secref{results} we present results regarding the performance of the implemented framework and compare these results with the other frameworks.%In section \secref{hyper-heuristics} we give a short introduction on hyper-heuristics. 

\section{Related work}
\seclab{parhyp}

Performing hyper-heuristics in parallel has the potential to speed up convergence towards good solutions or make the result more robust. This research domain however is currently quite sparse. \emph{Leon, Miranda and Segura}\cite{} implemented a parallel hyper-heuristic using a \emph{multi-objective self-adaptive Island-based model}.

\paragraph{}
\emph{Multiobjectivisation} is a process where the initial evaluation function is divided into several somehow similar functions. Such decomposition allows the system to escape from a local optimum by one evaluation function by using another one. A problem with multiobjectivisation however is that the different objectives can interfere and cancel each other out. In order to prevent this one can calculate a weighted sum of the different objectives. This however introduces new parameters. Determining optimal parameter settings is quite hard.

\paragraph{}
The system focuses on genetic algorithms where each process maintains a set of solutions called a \emph{deme}. In each iteration one or more solutions are selected. By using a \emph{recombination operator} who take two or more solutions, the features of two solutions are recombined into a new solution. In an \emph{island-based} approach, solutions are occasionally exchanged between the different processes. The topology determining which processes exchange solutions is modified dynamically.

\paragraph{}
The system works in the \emph{master-slave} paradigm. A set of processes called \emph{workers} each execute a genetic algorithm. Parameters like the recombination operator are assigned by a special process called the \emph{master island}. When a stop criterion is reached, a worker sends the results to the \emph{master island} and obtains a new \emph{execution strategy}. Work is continued using the final set of solutions of the previous run.%The \emph{master island} decides which \emph{low-level configuration} will be applied at each \emph{worker}%One processor is called the \emph{master island} while the other processors

\paragraph{}
The framework is tested with the \emph{Antenna Positioning Problem (APP)}\cite{} and the \emph{Frequency Assignment Problem (FAP)}\cite{}. The researchers report a \emph{speed-up} but the results but the results are not comparable with tailor-based sequential approaches.

%\paragraph{}
%\emph{Rattadilok, Gaw and Kwan} furthermore implemented a parallel hyper-heuristic to solve scheduling problems. %They consider a set of agents who aim to schedule their tasks satisfying the given constraints bu

\todo{ander systeem bespreken?}

\section{The \emph{ParHyFlex} framework}
\seclab{parhyflex}

\subsection{\emph{HyFlex}}
In 2009 \emph{Burke et al.}\cite{} published a framework implemented in Java supporting the implementation of hyper-heuristics. One implements a problem by providing an implementation on how a solution is represented together with transition functions and an evaluation function. Hyper-heuristic can be implemented by calling the different transition and evaluation functions. Therefore the algorithm aims to solve the problem without any knowledge about the problem, neither does it know any details about the different transition functions. Therefore one can use a hyper-heuristic is implemented to solve a large range of optimization problems.

\subsection{Overview}

\emph{ParHyFlex}\footnote{The source code is available at \url{http://goo.gl/AyvHA}.} is a variant of the \emph{HyFlex} framework intended to make it easy to run hyper-heuristics in parallel. Using the framework, one can potentially implement a hyper-heuristic without any knowledge about the algorithm running on parallel systems. The framework is implemented in Java and communication is handled using the popular Message Passing Interface (MPI) protocol.

\paragraph{}
The implementation uses a peer-to-peer approach where each process runs its own (potentially different) hyper-heuristic. Occasionally solutions are shared among processes. Since similar solutions will probably have a similar fitness-value, it can be profitable to prevent the processes from exploring solutions in the same neighborhood. Finally, the framework provides a communication mechanism so the different hyper-heuristics can cooperate with each other.

\paragraph{}
Figure \ref{fig:parhyflexstructure} shows how the framework is structured. The lower components specify a given problem using a set of transition functions, a set of evaluation functions, one or more distance functions, an initialization function and a set of \emph{hypothesis generators}.
\begin{figure}[hbt]
\centering
\def\sc{1.45}\input{parhyflexstructure.tex}
\caption{Structure of the \emph{ParHyFlex} framework.}
\label{fig:parhyflexstructure}
\end{figure}

\paragraph{}
We first introduce some concepts.

\begin{definition}[Enforceable constraint]
An \emph{enforceable constraint} $e$ is a 3-tuple $e=\tupl{c,e^+,e^-}$ with $e_0:\calS\rightarrow\BoolSet$ a constraint, $e^+:\calS\rightarrow\calS$ a function slightly modifying a solution such that the resulting solution satisfies the constraint $c$, and $e^-:\calS\rightarrow\calS$ a function that modifies a solution such that the resulting solution does not satisfy the constraint. The set of all enforceable constraints for a given problem $P$ is denoted by $\calE_P$.
\end{definition}

\begin{definition}[Hypothesis generator]
A \emph{hypothesis generator} is a problem dependent function $h_P:\calS^{n_h}\rightarrow\calE_P$ that generates an \emph{enforceable constraint} out of one or more \emph{solutions}.
\end{definition}

\begin{definition}[Experience set]
An \emph{experience set} is a 
\end{definition}

\begin{definition}[Search space]
A \emph{search space} $\calA$ is a subset of the set of configurations $\calA\subseteq\calS$. In our definition, we represent a search space by a tuple $\calA=\tupl{A^+,A^-}$ where $A^+$ and $A^-$ are sets of enforceable constraints. $A^+$ is called the \emph{positive set} and $A^-$ the negative set. A search space $\calA$ contains a solution $s\in\calS$ if the constraint $c$ of at least one enforceable constraint $e$ in the positive $e\in A^+$ is satisfied and all the constraints of the enforceable constraints in the negative set $A^-$ fail. A solution $s\notin\calA$ is \emph{corrected} with respect to $\calA$ by applying a the positive transition function $e^+$ of an enforceable constraint $e\in A^+$ in the positive set and the negative transition functions $e^-$ of all the enforceable constraints $e\in A^-$ in the negative set.
\end{definition}

\subsection{Exchanging solutions}
\seclab{exchangingsolutions}
As discussed before, the \emph{island model}\cite{} is a paradigm in which different processes exchange solutions to speed up convergence. The framework provides different exchange strategies and the solutions are exchanged over unreliable asynchronous communication.% who take as input two or more solutions

\subsection{Generating experience}
\seclab{generatingexperience}
Modern SAT solvers try to speed up the search for a correct solution by learning new clauses on the fly. Such constraints can be considered experience. An advantage of such experience is that it can be shared with other processes and therefore speed up the search.

\paragraph{}
A similar concept is implemented in \emph{ParHyFlex}. The system considers experience to be a set of enforceable constraints who are probably true. This is in contrast with clause learners who only learn clauses who are certainly true.

\paragraph{}
In order to generate such constraints, one needs a function that has knowledge of the problem and can generate constraints based on a set of solutions, a hypothesis generator. The enforceable constraints generated by a hypothesis generator are stored in the experience set. This set maintains a fixed number of elements. Occasionally elements are eliminated to make room for other enforceable constraints. This procedure is discussed in Subsection \sscref{maintainingexperience}.

\subsection{Controlling the search space}
\seclab{controllingsearchspace}
SAT solvers try to exploit the learned clauses by eliminating large parts of the search tree. Based on the \emph{experience set} introduced in the previous subsection, one can manipulate the set of considered solutions as well. Therefore we first introduce the concept of a \emph{search space}.
\paragraph{}
Constraints in the \emph{search space} can potentially interact with each other: one \emph{enforceable constraint} can undo the modification of another one. Resolving such conflicts can be computationally expensive and is potentially impossible. The \emph{ParHyFlex} framework does not handle such interactions. A search space is enforced in a \emph{fuzzy way}: occasionally \emph{corrected} solutions will not be part of the intended \emph{search space}.

\paragraph{}
One can generate a \emph{search space} by using a copying subset of the \emph{enforceable constraints} in the \emph{experience set} to the \emph{positive set}. When machines search the same region, there is a risk that most machines get stuck in similar local optima. Escaping these optima can be quite cumbersome since the exchanged solutions are similar as well. \emph{ParHyFlex} aims to prevent this by negotiating about a new search space: when a machine uses a certain constraint in the \emph{positive set}, the other machines will put this constraint in their \emph{negative set}. Occasionally new \emph{search spaces} are negotiated so eventually the entire set of solutions is accessible.

\subsection{Maintaining experience}
\ssclab{maintainingexperience}
Generated \emph{enforceable constraints} are not guaranteed to be true. Therefore the system should be aware of new solutions and continuously checks if strong solutions still satisfy these constraints. This is a task that is handled by the \emph{ParHyFlex} framework. Each time a new solution is generated, the system checks which constraints are satisfied. Based on the fitness-value of the solution, one can evaluate the \emph{enforceable constraints}. Occasionally the system removes one or more of these constraints if good solutions no longer satisfy these constraints.

\paragraph{}
Even when the generated solutions satisfying a constraint yield better results, this does not necessarily mean that this constraint is true for the best solutions. For instance a large set of suboptimal solutions can satisfy the constraint while better solutions don't satisfy the constraint at all. Since the \emph{enforceable constraints} in the \emph{experience set} eventually form the \emph{search space}, such constraints can prevent further improvement. Therefore this mechanism sometimes eliminates constraints who are considered to perform well. The system uses a probabilistic mechanism where the probability of elimination is proportional to the performance of the constraint. Eventually however, every constraint will be eliminated.%Such constraints are not guaranteed to be true, therefore the system continuous checks if the newly generated solutions still satisfy these constraints. If the generated constraints generally are satisfied by strong solutions, the system is likely to keep the constraint.

\subsection{Exchanging experience}
\seclab{exchangingexperience}
Since each machine is constrained by a \emph{search space}, the generated solutions are somehow similar. Therefore the evaluation of \emph{enforceable constraints} is quite subjective. In order to yield better results, a part of the \emph{experience set} is occasionally shared with the other processors. This gives the opportunity to evaluate the constraints in a different setting. Potentially the constraints can become part of the \emph{search space} of a different processor.%Therefore strong solutions generated by one machine may satisfy a certain \emph{enforceable constraint} while strong solutions 
% Since it is a common belief that similar solutions are more or less equally strong, we expect we can find interesting regions based on the solutions in the neighborhood. When such solutions are found, it is therefore 

\subsection{Implementing a solution}
The lower components in figure \ref{fig:parhyflexstructure} show which aspects should be implemented when specifying a problem. The transition functions are divided into four categories: mutation, local search, ruin recreate and crossover. This distinction originates from the \emph{HyFlex} framework and provides the hyper-heuristic with some basic information. One does not need to provide a transition function for each type except the hyper-heuristic requires this. Multiobjectivisation is supported as well: one minimally provides the main objective but additional objectives can be implemented. Since the processes exchange 

\section{Results}
\seclab{results}

\subsection{Environment}
In order to test the framework, we have implemented a hyper-heuristic based on the \emph{AdapHH}\cite{} algorithm of Mustafa M\i{}s\i{}r. The algorithm was tested on the following problems: \emph{Maximal Satisfiability}, \emph{Frequency Assignment} and \emph{Circle Positioning}. The problems are briefly described in subsection \sscref{problemset}.%In the circle positioning problem, one tries to determine the location of a set of circles withing a large circle reducing the overlap of each pair of two circles.
\paragraph{}
The tests were performed on machines with an \emph{Intel i5 2400} processor\footnote{$4\times 3.10\mbox{ GHz}$ , $6\mbox{ MiB}$ cache.} and $3.7\mbox{ GiB}$ memory running the \emph{Ubuntu 12.04} operating system. The network uses \emph{Gigabit Ethernet} and is organized with a centralized switch.

\subsection{Problem Set}
\ssclab{problemset}
The \emph{Maximal Satisfiability Problem (Max-Sat)}\cite{} is a popular problem where given a set of clauses the algorithm searches for a configuration such that the boolean variables satisfy the largest amount of clauses.

\paragraph{}
The \emph{Circle Positioning Problem (CPP)}\cite{} considers a set of circles\footnote{Two circles may differ in radius.} and a large circle. One can search locations for these circles such that the total area of overlap and the area outside the large circle is minimized. Since the domains of the $x$ and $y$ coordinates of the circles are all representable floating point numbers, this problem cannot easily be solved by a \emph{branch-and-bound algorithm}.

\paragraph{}
Finally in the \emph{Frequency Assignment Problem (FAP)}\cite{} one is given a set of transceivers $\accl{t_1,\ldots,t_n}$. Each transceiver $t_i$ can operate on a set of frequencies $\accl{f_{i\,1},\ldots,f_{i\ m_i}}$ some of the transceivers can operate on the same frequency. Each of the transceivers operates in one of the sectors $\accl{s_1,\ldots,s_k}$. A transceiver $t_i$ is placed in sector \fun{s}{t_i} and some transceivers share a sector. One tries to find a configuration where a transceiver $t_i$ is assigned a frequency $\fun{f}{t_i}$ and the total interference is minimized. The interference between two transceivers $t$ and $u$ is defined as:
\begin{equation}
\funm{interference}{t,u}=\guard{
\infty&s_t=s_u\wedge\abs{\fun{f}{t}-\fun{f}{u}}<2\\
\funm{erf}{c_1-\mu_{s_t\,s_u}/\sigma_{s_t\,s_u}}&s_t=s_u\wedge\mu_{s_t\,s_u}>0\wedge\abs{\fun{f}{t}-\fun{f}{u}}=0\\
\funm{erf}{c_1-c_2-\mu_{s_t\,s_u}/\sigma_{s_t\,s_u}}&s_t=s_u\wedge\mu_{s_t\,s_u}>0\wedge\abs{\fun{f}{t}-\fun{f}{u}}=1\\
0&\mbox{otherwise}
}
\end{equation}
Where $s_t$ and $s_u$ are the sectors of the transceivers $t$ and $u$. $\mu_{s_t\,s_u}$ and $\sigma_{s_t\,s_u}$ represent the mean and average in the signal-to-inference (C/I) ratio between the sectors $s_t$ and $s_u$. $c_1$ and $c_2$ are the threshold values of acceptable quality. Finally $\funm{erf}{x}$ is defined as the the error-function. The total interference is calculated by taking the sum over every two different transceivers. Instead of infinity most implementations use a large constant to distinct between different amounts of total interference. This problem is tackled by the framework of \emph{Leon, Miranda and Segura} as discussed in section \secref{parhyp}.

\subsection{Experimental results}
\todo{Wachten op resultaten voor CPP en FAP.}


\section{Conclusions and Further Work}
\todo{Wachten op resultaten voor CPP en FAP.}

\bibliographystyle{plain}
\bibliography{referenties}
\end{document}
